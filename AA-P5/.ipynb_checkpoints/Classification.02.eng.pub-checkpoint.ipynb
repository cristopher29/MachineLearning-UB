{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification 02\n",
    "\n",
    "# Resampling and evaluation of prediction methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Josep Fortiana 2019-10-29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this laboratory is to attain a practical knowledge of some of the available procedures to assess the quality of prediction methods, classification (categorical response) and regression (numerical response), with a particular emphasis on detecting and avoiding overfitting.\n",
    "\n",
    "We consider four procedures or families of procedures: \n",
    "    \n",
    "1. Hold-out: Split the dataset in two parts, a training subset and a 'test' subset. The first one is used to train (estimate or learn parameters of) the prediction method. Meanwhile, the 'test' subset is held out, keeping it apart to rule out the optimistic bias inherent in using the same samples for learning to predict and for evaluating goodness of prediction.\n",
    "\n",
    "2. $k$-fold cross-validation,  \n",
    "\n",
    "3. Leave-one-out (LOO), \n",
    "\n",
    "4. Bootstrap.\n",
    "\n",
    "We already know the first procedure. The second one is a systematic repetition of hold-out in such a way that consecutively each individual is in a training subset and in a test subset. The third procedure is an extreme $k$-fold cross-validation, where $k=n$, the number of individuals in the sample, in which the test subset is a single individual and the training subset  the remaining $(n-1)$ restantes. \n",
    "\n",
    "The fourth procedure is an application of a much more general statistical concept, the _bootstrap,_ which we review in Section A, before going to its application with the other procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and prediction methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. `wine` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wine` data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines.\n",
    "\n",
    "They can be found in the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/), which hosts many documented data sets to be used as benchmarks in evaluating Machine Learning methods and algorithms. Alternatively, should the link be broken, you can find the `.csv` file in the Virtual Campus. The following description is taken from the UCI website:\n",
    "\n",
    "I think that the initial data set had around 30 variables, but for some reason I only have the 13 dimensional version. I had a list of what the 30 or so variables were, but a.) I lost it, and b.), I would not know which 13 variables are included in the set.\n",
    "\n",
    "The attributes are:\n",
    "\n",
    "01. Alcohol\n",
    "\n",
    "02. Malic acid\n",
    "\n",
    "03. Ash\n",
    "\n",
    "04. Alcalinity of ash\n",
    "\n",
    "05. Magnesium\n",
    "\n",
    "06. Total phenols\n",
    "\n",
    "07. Flavonoids\n",
    "\n",
    "08. Nonflavonoid phenols\n",
    "\n",
    "09. Proanthocyanins\n",
    "\n",
    "10. Color intensity\n",
    "\n",
    "11. Hue\n",
    "\n",
    "12. OD280/OD315 of diluted wines\n",
    "\n",
    "13. Proline\n",
    "\n",
    "\n",
    "In a classification context, this is a well posed problem with \"well behaved\" class structures. A good data set for first testing of a new classifier, but not very challenging.\n",
    "\n",
    "Since the `.csv` file has no first row with variable names we must set `header=FALSE` in the `read.csv` call (see default values for the optional parameters in the help). \n",
    "\n",
    "The casting `as.factor()` command has the purpose of conveying the fact that this variable is qualitative, so the R interpreter can use it as such.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine.url<-\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "#wine<-read.csv(wine.url,header=FALSE)\n",
    "wine<-read.csv(\"wine.csv\",header=FALSE)\n",
    "colnames(wine)<-c(\"Type\",\"Alcohol\",\"Malic\",\"Ash\", \"Alcalinity\",\"Magnesium\",\"Phenols\",\"Flavonoids\", \n",
    "                  \"Nonflavonoids\",\"Proanthocyanins\",\"Color\",\"Hue\", \"Dilution\",\"Proline\")\n",
    "wine$Type <- as.factor(wine$Type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aa. `wine` dataset and $k$-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aa1. Hold-out\n",
    "\n",
    "Split the whole dataset into two subsets, `train` with $\\approx60\\%$ of data, and `test` the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Type      Alcohol          Malic            Ash          Alcalinity   \n",
       " 1:59   Min.   :11.03   Min.   :0.740   Min.   :1.360   Min.   :10.60  \n",
       " 2:71   1st Qu.:12.36   1st Qu.:1.603   1st Qu.:2.210   1st Qu.:17.20  \n",
       " 3:48   Median :13.05   Median :1.865   Median :2.360   Median :19.50  \n",
       "        Mean   :13.00   Mean   :2.336   Mean   :2.367   Mean   :19.49  \n",
       "        3rd Qu.:13.68   3rd Qu.:3.083   3rd Qu.:2.558   3rd Qu.:21.50  \n",
       "        Max.   :14.83   Max.   :5.800   Max.   :3.230   Max.   :30.00  \n",
       "   Magnesium         Phenols        Flavonoids    Nonflavonoids   \n",
       " Min.   : 70.00   Min.   :0.980   Min.   :0.340   Min.   :0.1300  \n",
       " 1st Qu.: 88.00   1st Qu.:1.742   1st Qu.:1.205   1st Qu.:0.2700  \n",
       " Median : 98.00   Median :2.355   Median :2.135   Median :0.3400  \n",
       " Mean   : 99.74   Mean   :2.295   Mean   :2.029   Mean   :0.3619  \n",
       " 3rd Qu.:107.00   3rd Qu.:2.800   3rd Qu.:2.875   3rd Qu.:0.4375  \n",
       " Max.   :162.00   Max.   :3.880   Max.   :5.080   Max.   :0.6600  \n",
       " Proanthocyanins     Color             Hue            Dilution    \n",
       " Min.   :0.410   Min.   : 1.280   Min.   :0.4800   Min.   :1.270  \n",
       " 1st Qu.:1.250   1st Qu.: 3.220   1st Qu.:0.7825   1st Qu.:1.938  \n",
       " Median :1.555   Median : 4.690   Median :0.9650   Median :2.780  \n",
       " Mean   :1.591   Mean   : 5.058   Mean   :0.9574   Mean   :2.612  \n",
       " 3rd Qu.:1.950   3rd Qu.: 6.200   3rd Qu.:1.1200   3rd Qu.:3.170  \n",
       " Max.   :3.580   Max.   :13.000   Max.   :1.7100   Max.   :4.000  \n",
       "    Proline      \n",
       " Min.   : 278.0  \n",
       " 1st Qu.: 500.5  \n",
       " Median : 673.5  \n",
       " Mean   : 746.9  \n",
       " 3rd Qu.: 985.0  \n",
       " Max.   :1680.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(wine)\n",
    "n<-nrow(wine)\n",
    "ntrain<-ceiling(0.6*n)\n",
    "ntest<-n-ntrain\n",
    "Itrain<-sample(1:n,ntrain,replace=FALSE)\n",
    "wine.train<-wine[Itrain,]\n",
    "wine.test<-wine[-Itrain,]\n",
    "Xtrain<-as.matrix(wine.train[,-1])\n",
    "ytrain<-wine.train[,1]\n",
    "Xtest<-as.matrix(wine.test[,-1])\n",
    "ytest<-wine.test[,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#install.packages(\"class\",dependencies=TRUE,repos=\"https://cloud.r-project.org\")\n",
    "require(class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix and misclassification error estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Predicted\n",
       "True  1  2  3\n",
       "   1 21  3  2\n",
       "   2  2 18  5\n",
       "   3  3  7 10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'For k =3,   Prob.err =  0.31 '</span>"
      ],
      "text/latex": [
       "'For k =3,   Prob.err =  0.31 '"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'For k =3,   Prob.err =  0.31 '</span>"
      ],
      "text/plain": [
       "[1] \"For k =3,   Prob.err =  0.31 \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "require(ISLR)\n",
    "require(caret)\n",
    "\n",
    "set.seed(400)\n",
    "ctrl <- trainControl(method=\"repeatedcv\",repeats = 3)\n",
    "knnFit <- train(ytrain, data = Xtrain, method = \"knn\", trControl = ctrl, preProcess = c(\"center\",\"scale\"),tuneLength = 20)\n",
    "knnFit\n",
    "\n",
    "k<-3\n",
    "y.hat<-knn(Xtrain,Xtest,ytrain,k )\n",
    "C<-table(\"True\"=ytest,\"Predicted\"=y.hat)\n",
    "P.err<-(ntest-sum(diag(C)))/ntest\n",
    "C\n",
    "sprintf(\"For k =%d,   Prob.err = %5.2f \", k, round(P.err,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which is the optimal $k$?\n",
    "\n",
    "Redo the above computation with several values of $k$ and decide which is the optimal $k$ according to the probability of misclassification.\n",
    "\n",
    "_Hint:_ After doing it _\"by hand\"_ you can try a systematic approach, building a table where the first column is `k` and the second column the estimated probability of misclassification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aa.2. k-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform $k$-fold cross-validation with some simple code. An alternative approach is to use functions from a dedicated R package. My personal prejudice is in favor of writing one's own code. Anyway you can see in the Appendix at the end of this notebook some possible such packages and you can judge by yourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfoldIndexes<-function(n,k){\n",
    "    l<-floor(n/k)\n",
    "    Indexes<-c(1,(1:k)*l)\n",
    "    Indexes[k+1]<-n\n",
    "    return(Indexes)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>59</li>\n",
       "\t<li>118</li>\n",
       "\t<li>178</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 59\n",
       "\\item 118\n",
       "\\item 178\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 59\n",
       "3. 118\n",
       "4. 178\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]   1  59 118 178"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>59</li>\n",
       "\t<li>118</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 59\n",
       "\\item 118\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 59\n",
       "3. 118\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]   1  59 118"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>59</li>\n",
       "\t<li>118</li>\n",
       "\t<li>178</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 59\n",
       "\\item 118\n",
       "\\item 178\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 59\n",
       "2. 118\n",
       "3. 178\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  59 118 178"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decide a 'K' for K-fold cross-validation (uppercase to avoid notation clash with the k in k-NN)\n",
    "n<-nrow(wine)\n",
    "K<-3\n",
    "J<-kfoldIndexes(n,K)\n",
    "J\n",
    "Lower<-J[-(K+1)]\n",
    "Upper<-J[-1]\n",
    "Lower\n",
    "Upper\n",
    "# Una random permutation of indexes\n",
    "I<-sample(1:n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Predicted\n",
      "True  1  2  3\n",
      "   1 19  0  1\n",
      "   2  2 16  7\n",
      "   3  2  7  5\n",
      "[1] 1\n",
      "[1] 0.4366197\n",
      "    Predicted\n",
      "True  1  2  3\n",
      "   1 15  1  2\n",
      "   2  0 17  6\n",
      "   3  2  5 12\n",
      "[1] 2\n",
      "[1] 0.3802817\n",
      "    Predicted\n",
      "True  1  2  3\n",
      "   1 20  0  2\n",
      "   2  2 13  9\n",
      "   3  0  3 12\n",
      "[1] 3\n",
      "[1] 0.3661972\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.437</li>\n",
       "\t<li>0.38</li>\n",
       "\t<li>0.366</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.437\n",
       "\\item 0.38\n",
       "\\item 0.366\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.437\n",
       "2. 0.38\n",
       "3. 0.366\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.437 0.380 0.366"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.394"
      ],
      "text/latex": [
       "0.394"
      ],
      "text/markdown": [
       "0.394"
      ],
      "text/plain": [
       "[1] 0.394"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k<-10# this is the 'k' in k-NN\n",
    "# Repeat with several 'k' and choose an optimal value.\n",
    "P.ERR<-rep(0,K)\n",
    "for (fold in 1:K){\n",
    "    Itest<-I[Lower[fold]:Upper[fold]]\n",
    "    wine.test<-wine[Itest,]\n",
    "    wine.train<-wine[-Itest,]\n",
    "    Xtrain<-as.matrix(wine.train[,-1])\n",
    "    ytrain<-wine.train[,1]\n",
    "    Xtest<-as.matrix(wine.test[,-1])\n",
    "    ytest<-wine.test[,1]\n",
    "    y.hat<-knn(Xtrain,Xtest,ytrain,k)\n",
    "    C<-table(\"True\"=ytest,\"Predicted\"=y.hat)\n",
    "    print(C)\n",
    "    print(fold)\n",
    "    P.ERR[fold]<-(ntest-sum(diag(C)))/ntest\n",
    "    print(P.ERR[fold])\n",
    "    }\n",
    "round(P.ERR,3)\n",
    "mean.p.err<-mean(P.ERR)\n",
    "round(mean.p.err,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aa.3. Leave-one-out _(LOO)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     [,1] [,2] [,3]\n",
      "[1,]   52    1    6\n",
      "[2,]    5   47   19\n",
      "[3,]    5   20   23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.315"
      ],
      "text/latex": [
       "0.315"
      ],
      "text/markdown": [
       "0.315"
      ],
      "text/plain": [
       "[1] 0.315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k<-6\n",
    "# Repeat with several 'k' and choose an optimal value.\n",
    "g<-nlevels(wine$Type)\n",
    "C<-matrix(0,nrow=g,ncol=g)\n",
    "for (i in 1:n){\n",
    "    wine.test<-wine[i,]\n",
    "    wine.train<-wine[-i,]\n",
    "    Xtrain<-as.matrix(wine.train[,-1])\n",
    "    ytrain<-wine.train[,1]\n",
    "    Xtest<-as.matrix(wine.test[,-1])\n",
    "    ytest<-wine.test[,1]\n",
    "    y.hat<-knn(Xtrain,Xtest,ytrain,k)\n",
    "    C[ytest,y.hat]=C[ytest,y.hat]+1\n",
    "    }\n",
    "print(C)\n",
    "p.err<-(n-sum(diag(C)))/n\n",
    "round(p.err,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aa.4.  _bootstrap_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 67\n",
      "    Predicted\n",
      "True  1  2  3\n",
      "   1 17  0  2\n",
      "   2  4 19  5\n",
      "   3  2 11  7\n",
      "[1] 73\n",
      "    Predicted\n",
      "True  1  2  3\n",
      "   1 22  0  0\n",
      "   2  3 18  8\n",
      "   3  3  8 11\n",
      "[1] 75\n",
      "    Predicted\n",
      "True  1  2  3\n",
      "   1 22  0  6\n",
      "   2  2 19 10\n",
      "   3  1  4 11\n",
      "[1] 66\n",
      "    Predicted\n",
      "True  1  2  3\n",
      "   1 17  1  4\n",
      "   2  1 20  5\n",
      "   3  0  8 10\n",
      "[1] 62\n",
      "    Predicted\n",
      "True  1  2  3\n",
      "   1 20  0  2\n",
      "   2  1 16 12\n",
      "   3  1  1  9\n",
      "[1] 62\n",
      "    Predicted\n",
      "True  1  2  3\n",
      "   1 19  0  2\n",
      "   2  1 18  3\n",
      "   3  4  6  9\n",
      "[1] 56\n",
      "    Predicted\n",
      "True  1  2  3\n",
      "   1 16  0  2\n",
      "   2  0 15  7\n",
      "   3  3  5  8\n",
      "[1] 71\n",
      "    Predicted\n",
      "True  1  2  3\n",
      "   1 21  0  2\n",
      "   2  2 18  9\n",
      "   3  3  8  8\n",
      "[1] 65\n",
      "    Predicted\n",
      "True  1  2  3\n",
      "   1 17  1  1\n",
      "   2  3 18  4\n",
      "   3  1 13  7\n",
      "[1] 63\n",
      "    Predicted\n",
      "True  1  2  3\n",
      "   1 20  0  1\n",
      "   2  1  9 14\n",
      "   3  1  3 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.358</li>\n",
       "\t<li>0.301</li>\n",
       "\t<li>0.307</li>\n",
       "\t<li>0.288</li>\n",
       "\t<li>0.274</li>\n",
       "\t<li>0.258</li>\n",
       "\t<li>0.304</li>\n",
       "\t<li>0.338</li>\n",
       "\t<li>0.354</li>\n",
       "\t<li>0.317</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.358\n",
       "\\item 0.301\n",
       "\\item 0.307\n",
       "\\item 0.288\n",
       "\\item 0.274\n",
       "\\item 0.258\n",
       "\\item 0.304\n",
       "\\item 0.338\n",
       "\\item 0.354\n",
       "\\item 0.317\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.358\n",
       "2. 0.301\n",
       "3. 0.307\n",
       "4. 0.288\n",
       "5. 0.274\n",
       "6. 0.258\n",
       "7. 0.304\n",
       "8. 0.338\n",
       "9. 0.354\n",
       "10. 0.317\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 0.358 0.301 0.307 0.288 0.274 0.258 0.304 0.338 0.354 0.317"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.31"
      ],
      "text/latex": [
       "0.31"
      ],
      "text/markdown": [
       "0.31"
      ],
      "text/plain": [
       "[1] 0.31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k<-7\n",
    "# Repeat with several 'k' and choose an optimal value.\n",
    "n<-nrow(wine)\n",
    "I<-1:n\n",
    "# Number of bootstrap resamples\n",
    "B<-10\n",
    "P.ERR<-rep(0,B)\n",
    "for (b in 1:B){\n",
    "    Ib<-sample(I,n,replace = TRUE)\n",
    "    oob<-I[is.na(match(I,Ib))]\n",
    "    Itest<-oob\n",
    "    ntest<-length(oob)\n",
    "    print(ntest)\n",
    "    wine.test<-wine[Itest,]\n",
    "    wine.train<-wine[-Itest,]\n",
    "    Xtrain<-as.matrix(wine.train[,-1])\n",
    "    ytrain<-wine.train[,1]\n",
    "    Xtest<-as.matrix(wine.test[,-1])\n",
    "    ytest<-wine.test[,1]\n",
    "    y.hat<-knn(Xtrain,Xtest,ytrain,k)\n",
    "    C<-table(\"True\"=ytest,\"Predicted\"=y.hat)\n",
    "    print(C)\n",
    "    P.ERR[b]<-(ntest-sum(diag(C)))/ntest\n",
    "    }\n",
    "round(P.ERR,3)\n",
    "mean.p.err<-mean(P.ERR)\n",
    "round(mean.p.err,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. `Auto` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description\n",
    "Gas mileage, horsepower, and other information for 392 vehicles.\n",
    "\n",
    "#### Format\n",
    "A data frame with 392 observations on the following 9 variables.\n",
    "\n",
    "01. `mpg`: miles per gallon.\n",
    "\n",
    "02. `cylinders`: Number of cylinders between 4 and 8.\n",
    "\n",
    "03. `displacement`: Engine displacement (cu. inches).\n",
    "\n",
    "04. `horsepower`: Engine horsepower.\n",
    "\n",
    "05. `weight`: Vehicle weight (lbs.).\n",
    "\n",
    "06. `acceleration`: Time to accelerate from 0 to 60 mph (sec.).\n",
    "\n",
    "07. `year`: Model year (modulo 100).\n",
    "\n",
    "08. `origin`: Origin of car (1. American, 2. European, 3. Japanese).\n",
    "\n",
    "09. `name`: Vehicle name.\n",
    "\n",
    "The orginal data contained 408 observations but 16 observations with missing values were removed.\n",
    "\n",
    "#### Source\n",
    "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. The dataset was used in the 1983 American Statistical Association Exposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#install.packages(\"ISLR\",dependencies=TRUE,repos=\"https://cloud.r-project.org\")\n",
    "require(ISLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data(Auto)\n",
    "str(Auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discard the 'name' variable, irrelevant for prediction\n",
    "Auto<-Auto[,-9]\n",
    "str(Auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ba.1 Hold-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ba.2 $k$-fold crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ba.3 Leave-one-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ba.4 Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. `SAheart` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `ElemStatLearn` package, `SAheart` is a data frame with 462 observations on the following 10 variables.\n",
    "\n",
    "01. `sbp`: systolic blood pressure.\n",
    "\n",
    "02. `tobacco`: cumulative tobacco (kg).\n",
    "\n",
    "03. `ldl`: low density lipoprotein cholesterol.\n",
    "\n",
    "04. `adiposity`: a numeric vector.\n",
    "\n",
    "05. `famhist`: family history of heart disease, a factor with levels `Absent`, `Present`.\n",
    "\n",
    "06. `typea`: type-A behavior.\n",
    "\n",
    "07. `obesity`: a numeric vector.\n",
    "\n",
    "08. `alcohol`: current alcohol consumption.\n",
    "\n",
    "09. `age`: age at onset\n",
    "\n",
    "10. `chd`: response, coronary heart disease\n",
    "\n",
    "##### Details\n",
    "\n",
    "A retrospective sample of males in a heart-disease high-risk region of the Western Cape, South Africa. There are roughly two controls per case of CHD. Many of the CHD positive men have undergone blood pressure reduction treatment and other programs to reduce their risk factors after their CHD event. In some cases the measurements were made after these treatments. These data are taken from a larger dataset, described in Rousseauw et al, 1983, South African Medical Journal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#install.packages(\"ElemStatLearn\",dependencies=TRUE,repos=\"https://cloud.r-project.org\")\n",
    "require(ElemStatLearn)\n",
    "data(SAheart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n<-nrow(SAheart)\n",
    "ntrain<-ceiling(0.60*n)\n",
    "Itrain<-sample(1:n,ntrain,replace=FALSE)\n",
    "n<-nrow(SAheart)\n",
    "ntrain<-ceiling(0.60*n)\n",
    "Itrain<-sample(1:n,ntrain,replace=FALSE)\n",
    "SAheart.train<-SAheart[Itrain,]\n",
    "SAheart.test<-SAheart[-Itrain,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ca. SAheart data with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAheart.logit1<-glm(chd~.,data=SAheart.train,family=binomial)\n",
    "summary(SAheart.logit1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of probabilities that the binary 0/1 response takes the value 1 (here `chd=1`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAheart.pred<-predict(SAheart.logit1,newdata=SAheart.test,type=\"response\")\n",
    "str(SAheart.pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _crisp_ prediction of 0 or 1 is obtained from the above by taking a cut point, e.g., $L=0.5$ (this is not a mandatory value, it may depend on the problem or on the _a priori_ probabilites) and assign to 0 or 1 according to whether the probability is smaller or larger than this threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAheart.pred.crisp<-1*(SAheart.pred>=0.5)\n",
    "C<-table(\"True\"=SAheart.test$chd,\"Predicted\"=SAheart.pred.crisp)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ca.1 Hold-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ca.2 $k$-fold crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ca.3 Leave-one-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ca.4 Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cb. `SAheart` with Fisher's linear discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require(MASS)\n",
    "SAheart.lda1<-lda(chd~.,data=SAheart.train)\n",
    "SAheart.pred<-predict(SAheart.lda1,newdata=SAheart.test)\n",
    "C<-table(\"True\"=SAheart.test$chd,\"Predicted\"=SAheart.pred$class)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cb.1 Hold-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cb.2 $k$-fold crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cb.3 Leave-one-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cb.4 Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cb. `SAheart` with Quadratic discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAheart.qda1<-qda(chd~.,data=SAheart.train)\n",
    "SAheart.pred<-predict(SAheart.qda1,newdata=SAheart.test)\n",
    "C<-table(\"True\"=SAheart.test$chd,\"Predicted\"=SAheart.pred$class)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. `Default` data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `ISLR` package. A simulated data set containing information on ten thousand customers. The aim here is to predict which customers will default on their credit card debt.\n",
    "\n",
    "A data frame with 10000 observations on the following 4 variables.\n",
    "\n",
    "01. `default`: A factor with levels `No` and `Yes` indicating whether the customer defaulted on their debt\n",
    "\n",
    "02. `student`: A factor with levels `No` and `Yes` indicating whether the customer is a student\n",
    "\n",
    "03. `balance`: The average balance that the customer has remaining on their credit card after making their monthly payment\n",
    "\n",
    "04. `income`: Income of customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#install.packages(\"ISLR\",dependencies=TRUE,repos=\"https://cloud.r-project.org\")\n",
    "require(ISLR)\n",
    "data(Default)\n",
    "str(Default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Da. `Default` data set with Fisher's linear discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n<-nrow(Default)\n",
    "ntrain<-ceiling(0.6*n)\n",
    "set.seed(24025)         # An arbitrary value, fixed for the sake of reproducibility of results\n",
    "Itrain<-sample(1:n,ntrain,replace=FALSE)\n",
    "Default.train<-Default[Itrain,]\n",
    "Default.test<-Default[-Itrain,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require(MASS)\n",
    "Default.lda<-lda(default~.,data=Default.train)\n",
    "Default.pred<-predict(Default.lda,newdata=Default.test)\n",
    "C<-table(\"True\"=Default.test$default,\"Predicted\"=Default.pred$class)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Smarket` data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an S&P Stock Market Data set. Daily percentage returns for the S&P 500 stock index between 2001 and 2005.\n",
    "Contained in the `ISLR` package as a `data.frame` with 1250 observations on the following 9 variables.\n",
    "\n",
    "01. `Year`: The year that the observation was recorded\n",
    "\n",
    "02. `Lag1`: Percentage return for previous day\n",
    "\n",
    "03. `Lag2`: Percentage return for 2 days previous\n",
    "\n",
    "04. `Lag3`: Percentage return for 3 days previous\n",
    "\n",
    "05. `Lag4`: Percentage return for 4 days previous\n",
    "\n",
    "06. `Lag5`: Percentage return for 5 days previous\n",
    "\n",
    "07. `Volume`: Volume of shares traded (number of daily shares traded in billions)\n",
    "\n",
    "08. `Today`: Percentage return for today\n",
    "\n",
    "09. `Direction`: A factor with levels `Down` and `Up` indicating whether the market had a positive or negative return on a given day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require(ISLR)\n",
    "data(Smarket)\n",
    "str(Smarket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: dedicated R packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many R packages contain functions implementing methods for validating prediction procedures, for instance:\n",
    "- `caret`, \n",
    "- `CVST`, \n",
    "- `cvTools`, \n",
    "- `dprep`, \n",
    "- `sortinghat`. \n",
    "\n",
    "One of them (`CVST`) is devoted to a validation technique more sophisticated than the four in this notebook, and the rest are generic, with application to some prediction methods than those in our course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
